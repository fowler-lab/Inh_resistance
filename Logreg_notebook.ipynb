{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e789fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "ML_data = pd.read_csv('ML_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace2539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ML_data[['METHOD_MIC','MUT_RESISTANCE','Site1_Distance','d_volume','d_MW',\t\\\n",
    "              'd_hydropathy', 'd_Pi', 'Depth']]\n",
    "\n",
    "# creates features numpy array\n",
    "features = df[df.columns[2:]].to_numpy()\n",
    "\n",
    "#creates resistance label column\n",
    "label = df['MUT_RESISTANCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba10fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
    "\n",
    "#create logistic regression pipeline with preprocessing \n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', LogisticRegression(max_iter=10000))])\n",
    "#create parameter grid with different preprocessing and classifier parameters\n",
    "param_grid = {'preprocessing':[StandardScaler(), MinMaxScaler(), RobustScaler(), None],\n",
    "              'classifier__C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#split data into training and test sets\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(features, label,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd7831ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>MUT_RESISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>55.605736</td>\n",
       "      <td>-26.7</td>\n",
       "      <td>-14.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>5.378177</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>48.271434</td>\n",
       "      <td>24.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>4.632459</td>\n",
       "      <td>-27.1</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1     2    3     4         5  MUT_RESISTANCE\n",
       "0      4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "5      4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "6      4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "19     4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "25     4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "...         ...   ...   ...  ...   ...       ...             ...\n",
       "889    4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "907    4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "917   55.605736 -26.7 -14.1  0.4 -0.02  5.378177             1.0\n",
       "1046  48.271434  24.1  26.0 -3.4  0.30  0.000000             1.0\n",
       "1049   4.632459 -27.1 -14.0 -0.1  0.08  0.000000             1.0\n",
       "\n",
       "[387 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates features and label dfs from unique mutations in the training split\n",
    "# NOTE - this section is being cleaned up - it will affect th rest of the code which doesnt account\n",
    "# for the second train test split\n",
    "X_train_df = pd.DataFrame(X_train1)\n",
    "y_train_df = pd.DataFrame(y_train1)\n",
    "CV_train = X_train_df.join(y_train_df)\n",
    "\n",
    "mutation_index_s = ML_data['MUTATION']\n",
    "mutation_index_pd = pd.Series(mutation_index_s)\n",
    "mutation_index = mutation_index_pd.to_frame()\n",
    "\n",
    "CV_training_and_mutations = CV_train.join(mutation_index, how = 'inner')\n",
    "CV_train_unique = CV_training_and_mutations.drop_duplicates(subset='MUTATION', keep = 'first')\n",
    "CV_train_unique.drop(['MUTATION'], axis = 1, inplace = True)\n",
    "\n",
    "features1 = CV_train_unique[CV_train_unique.columns[:-1]].to_numpy()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295aab05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.63245877e+00, -2.71000000e+01, -1.40000000e+01,\n",
       "        -1.00000000e-01,  8.00000000e-02,  0.00000000e+00],\n",
       "       [ 4.63245877e+00, -2.71000000e+01, -1.40000000e+01,\n",
       "        -1.00000000e-01,  8.00000000e-02,  0.00000000e+00],\n",
       "       [ 4.63245877e+00, -2.71000000e+01, -1.40000000e+01,\n",
       "        -1.00000000e-01,  8.00000000e-02,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 5.56057361e+01, -2.67000000e+01, -1.41000000e+01,\n",
       "         4.00000000e-01, -2.00000000e-02,  5.37817746e+00],\n",
       "       [ 4.82714341e+01,  2.41000000e+01,  2.60000000e+01,\n",
       "        -3.40000000e+00,  3.00000000e-01,  0.00000000e+00],\n",
       "       [ 4.63245877e+00, -2.71000000e+01, -1.40000000e+01,\n",
       "        -1.00000000e-01,  8.00000000e-02,  0.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e076eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_strat: best estimator: \n",
      " Pipeline(steps=[('preprocessing', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_strat: best cross-validation score : 0.9669887525952614 \n",
      "\n",
      "grid_strat: test set average accuracy : 0.9686492821564606\n"
     ]
    }
   ],
   "source": [
    "#Grid search with stratified cross validation\n",
    "grid_strat = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid_strat.fit(X_train, y_train)\n",
    "print ('grid_strat: best estimator: \\n', grid_strat.best_estimator_)\n",
    "print ('grid_strat: best cross-validation score :', grid_strat.best_score_, '\\n')\n",
    "print ('grid_strat: test set average accuracy :', \n",
    "       accuracy_score(y_test, grid_strat.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b042673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold: best estimator: \n",
      " Pipeline(steps=[('preprocessing', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_kfold: best cross-validation score : 0.9670864088452614 \n",
      "\n",
      "grid_kfold: test set average accuracy : 0.9686492821564606\n"
     ]
    }
   ],
   "source": [
    "#Grid search with kfold cross validation\n",
    "Kfold = KFold(n_splits=5)\n",
    "grid_kfold = GridSearchCV(pipe, param_grid, cv=Kfold)\n",
    "grid_kfold.fit(X_train, y_train)\n",
    "print ('grid_kfold: best estimator: \\n', grid_kfold.best_estimator_)\n",
    "print ('grid_kfold: best cross-validation score :', grid_kfold.best_score_, '\\n')\n",
    "print ('grid_kfold: test set average accuracy :', \n",
    "       accuracy_score(y_test, grid_kfold.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130c6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold_shuffle: best estimator: \n",
      " Pipeline(steps=[('preprocessing', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_kfold_shuffle: best cross-validation score:  0.9664026242672203\n",
      "grid_kfold_shuffle: test set average accuracy:  0.9686492821564606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Search with shuffled cross validation\n",
    "Kfold_shuffle=KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_kfold_shuffle = GridSearchCV(pipe, param_grid, cv=Kfold_shuffle)\n",
    "grid_kfold_shuffle.fit(X_train, y_train)\n",
    "print ('grid_kfold_shuffle: best estimator: \\n', grid_kfold_shuffle.best_estimator_)\n",
    "print ('grid_kfold_shuffle: best cross-validation score: ', grid_kfold_shuffle.best_score_)\n",
    "print ('grid_kfold_shuffle: test set average accuracy: ', \n",
    "       accuracy_score(y_test, grid_kfold_shuffle.predict(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f965862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_strat: best estimator: \n",
      " Pipeline(steps=[('preprocessing', RobustScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_strat: best cross-validation score:  0.9992655553162131\n",
      "grid_strat: test set average precision:  0.9993442441936968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with stratified cross validation\n",
    "#use decision function to calculate average_precision\n",
    "grid_strat = GridSearchCV(pipe, param_grid, cv=5, scoring='average_precision')\n",
    "grid_strat.fit(X_train, y_train)\n",
    "print ('grid_strat: best estimator: \\n', grid_strat.best_estimator_)\n",
    "print ('grid_strat: best cross-validation score: ', grid_strat.best_score_)                  \n",
    "print ('grid_strat: test set average precision: ', \n",
    "       average_precision_score(y_test, grid_strat.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2625492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold: best estimator: \n",
      " Pipeline(steps=[('preprocessing', RobustScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_kfold: best cross-validation score:  0.999262665822004\n",
      "grid_kfold test set average precision:  0.9993442441936968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with kfold cross validation\n",
    "#use decision function to calculate average_precision\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_kfold = GridSearchCV(pipe, param_grid, cv=kfold, scoring='average_precision')\n",
    "grid_kfold.fit(X_train, y_train)\n",
    "print ('grid_kfold: best estimator: \\n', grid_kfold.best_estimator_)\n",
    "print ('grid_kfold: best cross-validation score: ', grid_kfold.best_score_)                  \n",
    "print ('grid_kfold test set average precision: ', \n",
    "       average_precision_score(y_test, grid_kfold.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ddacede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold_shuffle: best estimator: \n",
      " Pipeline(steps=[('preprocessing', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=1, max_iter=10000))])\n",
      "grid_kfold_shuffle: best cross-validation score:  0.9992622667671277\n",
      "grid_kfold_shuffle test set average precision:  0.9993395811952269 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with shuffled cross validation\n",
    "#use decision function to calculate average_precision\n",
    "kfold_shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_kfold_shuffle = GridSearchCV(pipe, param_grid, cv=kfold_shuffle, scoring='average_precision')\n",
    "grid_kfold_shuffle.fit(X_train, y_train)\n",
    "print ('grid_kfold_shuffle: best estimator: \\n', grid_kfold_shuffle.best_estimator_)\n",
    "print ('grid_kfold_shuffle: best cross-validation score: ', grid_kfold_shuffle.best_score_)                  \n",
    "print ('grid_kfold_shuffle test set average precision: ', \n",
    "       average_precision_score(y_test, grid_kfold_shuffle.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4c78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_strat: best estimator: \n",
      " Pipeline(steps=[('preprocessing', RobustScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_strat: best cross-validation score:  0.9854838109412656\n",
      "grid_strat: test set AUC:  0.98542692769339 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with stratified cross validation\n",
    "#use decision function to calculate AUC\n",
    "\n",
    "grid_strat = GridSearchCV(pipe, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_strat.fit(X_train, y_train)\n",
    "print ('grid_strat: best estimator: \\n', grid_strat.best_estimator_)\n",
    "print ('grid_strat: best cross-validation score: ', grid_strat.best_score_)                  \n",
    "print ('grid_strat: test set AUC: ', \n",
    "       roc_auc_score(y_test, grid_strat.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4ccc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold: best estimator: \n",
      " Pipeline(steps=[('preprocessing', RobustScaler()),\n",
      "                ('classifier', LogisticRegression(C=0.01, max_iter=10000))])\n",
      "grid_kfold: best cross-validation score:  0.9855039769467536\n",
      "grid_kfold test set AUC:  0.98542692769339 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with kfold cross validation\n",
    "#use decision function to calculate AUC\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_kfold = GridSearchCV(pipe, param_grid, cv=kfold, scoring='roc_auc')\n",
    "grid_kfold.fit(X_train, y_train)\n",
    "print ('grid_kfold: best estimator: \\n', grid_kfold.best_estimator_)\n",
    "print ('grid_kfold: best cross-validation score: ', grid_kfold.best_score_)                  \n",
    "print ('grid_kfold test set AUC: ', \n",
    "       roc_auc_score(y_test, grid_kfold.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96eeae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_kfold_shuffle: best estimator: \n",
      " Pipeline(steps=[('preprocessing', StandardScaler()),\n",
      "                ('classifier', LogisticRegression(C=1, max_iter=10000))])\n",
      "grid_kfold_shuffle: best cross-validation score:  0.9853684726574234\n",
      "grid_kfold_shuffle test set AUC:  0.9853213857042341 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grid search with with shuffled kfold cross validation\n",
    "#use decision function to calculate AUC\n",
    "kfold_shuffle = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_kfold_shuffle = GridSearchCV(pipe, param_grid, cv=kfold_shuffle, scoring='roc_auc')\n",
    "grid_kfold_shuffle.fit(X_train, y_train)\n",
    "print ('grid_kfold_shuffle: best estimator: \\n', grid_kfold_shuffle.best_estimator_)\n",
    "print ('grid_kfold_shuffle: best cross-validation score: ', grid_kfold_shuffle.best_score_)                  \n",
    "print ('grid_kfold_shuffle test set AUC: ', \n",
    "       roc_auc_score(y_test, grid_kfold_shuffle.decision_function(X_test)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aeec7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision-recall curve for logistic regression (StandardScaler(), C=100)')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use best preprocessing (standard scaler) and parameters (c=100) for av. precision\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), \n",
    "                 ('classifier', LogisticRegression(C=100, max_iter=10000))])\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, random_state=0)\n",
    "pipe.fit(X_train, y_train)\n",
    "predict = (pipe.decision_function(X_test))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predict)\n",
    "\n",
    "plt.plot(precision, recall, label='LogReg')\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], '^', c='k', \n",
    "          markersize=10, label='threshold zero ', fillstyle='none', mew=2)\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Precision-recall curve for logistic regression (StandardScaler(), C=100)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446d97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
